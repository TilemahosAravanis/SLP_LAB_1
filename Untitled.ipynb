{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2a95d2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import sys\n",
    "import contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0dd0ee45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\r\n",
      "[nltk_data]     /home/tilemahos/nltk_data...\r\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\r\n"
     ]
    }
   ],
   "source": [
    "# Step 1 \n",
    "\n",
    "!python fetch_gutenberg.py > data/gutenberg.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d20abe83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2\n",
    "\n",
    "# Read the gutenberg.txt file word by word\n",
    "# and create a disctionary that holds as keys the tokens(words) and as values the number of appearance\n",
    "Dict = {}\n",
    "with open('./data/gutenberg.txt') as file:\n",
    "    # reading each line   \n",
    "    for line in file:\n",
    "        # reading each word       \n",
    "        for word in line.split():\n",
    "            if word not in Dict:\n",
    "                Dict[word] = 1\n",
    "            else:\n",
    "                Dict[word] = Dict[word] + 1\n",
    "\n",
    "# Filter rare tokens\n",
    "Dict = {key: val for key, val in Dict.items() if val >= 5}\n",
    "        \n",
    "# Write the Dict in an output file\n",
    "with open(\"./vocab/vocab.txt\",'w') as f:\n",
    "    for word in Dict.keys():\n",
    "        f.write(\"{}\\t{}\\n\".format(word,Dict[word]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "263c528f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3\n",
    "\n",
    "# Create chars.syms containing all ascii characters indexed\n",
    "with open(\"./vocab/chars.syms\",'w') as f:\n",
    "    f.write(\"<eps>\\t0\\n\")\n",
    "    for i in range(97,123):\n",
    "        f.write(\"{}\\t{}\\n\".format(chr(i),i-96))\n",
    " \n",
    " # Create words.syms containing all words in corpus indexed\n",
    "with open(\"./vocab/words.syms\",'w') as f:\n",
    "    i = 0\n",
    "    f.write(\"<eps>\\t0\\n\")\n",
    "    i = i+1\n",
    "    for word in Dict.keys():\n",
    "        f.write(\"{}\\t{}\\n\".format(word,i))\n",
    "        i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a74ea7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4\n",
    "\n",
    "# Levenhstein .fst\n",
    "\n",
    "with open(\"./fsts/L.fst\",'w') as f:\n",
    "    for i in range(97,123):\n",
    "        f.write(\"0\\t0\\t{}\\t{}\\t0\\n\".format(chr(i),chr(i))) # chr -> chr\n",
    "        f.write(\"0\\t0\\t{}\\t<eps>\\t1\\n\".format(chr(i))) # chr -> <eps>\n",
    "        f.write(\"0\\t0\\t<eps>\\t{}\\t1\\n\".format(chr(i))) # <eps> -> chr\n",
    "        for j in range(97,123):\n",
    "            if j != i:\n",
    "                f.write(\"0\\t0\\t{}\\t{}\\t1\\n\".format(chr(i),chr(j))) # chr -> chr\n",
    "    f.write(\"0\\t0\\n\") # end state\n",
    "                \n",
    "!fstcompile -isymbols=./vocab/chars.syms -osymbols=./vocab/chars.syms ./fsts/L.fst ./fsts/L.binfst\n",
    "!fstdraw -isymbols=./vocab/chars.syms -osymbols=./vocab/chars.syms -portrait ./fsts/L.binfst | dot -Tpng >./fsts/L.png\n",
    "!display ./fsts/L.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8292ec77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5\n",
    "\n",
    "# Dictionary acceptor .fst\n",
    "\n",
    "with open(\"./fsts/V.fst\",'w') as f:\n",
    "    j = 0\n",
    "    for word in Dict.keys():\n",
    "        i = 0\n",
    "        for letter in word:\n",
    "            if i == 0:\n",
    "                f.write(\"{}\\t{}\\t{}\\t{}\\t0\\n\".format(i,j+1,letter,word)) # word[0] -> word\n",
    "                j = j+1\n",
    "            else:    \n",
    "                f.write(\"{}\\t{}\\t{}\\t<eps>\\t0\\n\".format(j,j+1,letter)) # word[i>0] -> <eps>\n",
    "                j = j+1\n",
    "            i = i+1\n",
    "        f.write(\"{}\\t0\\n\".format(j)) # end state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "59c9f5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "!fstcompile -isymbols=./vocab/chars.syms -osymbols=./vocab/words.syms ./fsts/V.fst ./fsts/V.binfst\n",
    "!fstrmepsilon ./fsts/V.binfst | fstdeterminize | fstminimize >./fsts/V_opt.binfst\n",
    "# !fstdraw -isymbols=./fsts/chars.syms -osymbols=./fsts/words.syms -portrait ./fsts/V_opt.binfst | dot -Tpng >./fsts/V_opt.png\n",
    "# !display ./fsts/V_opt.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3418a95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cut"
     ]
    }
   ],
   "source": [
    "# Step 6\n",
    "\n",
    "# Compose L (Levensthein) with V (Dictionary acceptor) to build the naive spell checker S\n",
    "\n",
    "!fstarcsort --sort_type=olabel ./fsts/L.binfst ./fsts/L.binfst\n",
    "!fstarcsort --sort_type=ilabel ./fsts/V_opt.binfst ./fsts/V_opt.binfst\n",
    "!fstcompose ./fsts/L.binfst ./fsts/V_opt.binfst ./fsts/S.binfst\n",
    "\n",
    "!./predict.sh ./fsts/S.binfst cwt \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f0bd7d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city"
     ]
    }
   ],
   "source": [
    "!./predict.sh ./fsts/S.binfst cit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "93eefd7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entreaty"
     ]
    }
   ],
   "source": [
    "!./predict.sh ./fsts/S.binfst antheaterry "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "25658229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True \n",
      "contented:\n",
      "False \n",
      "contenpted\n",
      "Corrected \n",
      "contented\n",
      "\n",
      "True \n",
      "beginning:\n",
      "False \n",
      "begining\n",
      "Corrected \n",
      "beginning\n",
      "\n",
      "True \n",
      "problem:\n",
      "False \n",
      "problam\n",
      "Corrected \n",
      "problem\n",
      "\n",
      "True \n",
      "driven:\n",
      "False \n",
      "dirven\n",
      "Corrected \n",
      "given\n",
      "\n",
      "True \n",
      "ecstasy:\n",
      "False \n",
      "exstacy\n",
      "Corrected \n",
      "ecstasy\n",
      "\n",
      "True \n",
      "juice:\n",
      "False \n",
      "guic\n",
      "Corrected \n",
      "guil\n",
      "\n",
      "True \n",
      "locally:\n",
      "False \n",
      "localy\n",
      "Corrected \n",
      "local\n",
      "\n",
      "True \n",
      "compare:\n",
      "False \n",
      "compair\n",
      "Corrected \n",
      "company\n",
      "\n",
      "True \n",
      "pronunciation:\n",
      "False \n",
      "pronounciation\n",
      "Corrected \n",
      "provocation\n",
      "\n",
      "True \n",
      "transportability:\n",
      "False \n",
      "transportibility\n",
      "Corrected \n",
      "respectability\n",
      "\n",
      "True \n",
      "minuscule:\n",
      "False \n",
      "miniscule\n",
      "Corrected \n",
      "ridicule\n",
      "\n",
      "True \n",
      "independent:\n",
      "False \n",
      "independant\n",
      "Corrected \n",
      "independent\n",
      "\n",
      "True \n",
      "arranged:\n",
      "False \n",
      "aranged\n",
      "Corrected \n",
      "ranged\n",
      "\n",
      "True \n",
      "poetry:\n",
      "False \n",
      "poartry\n",
      "Corrected \n",
      "party\n",
      "\n",
      "True \n",
      "level:\n",
      "False \n",
      "leval\n",
      "Corrected \n",
      "legal\n",
      "\n",
      "True \n",
      "basically:\n",
      "False \n",
      "basicaly\n",
      "Corrected \n",
      "sickly\n",
      "\n",
      "True \n",
      "triangular:\n",
      "False \n",
      "triangulaur\n",
      "Corrected \n",
      "triangular\n",
      "\n",
      "True \n",
      "unexpected:\n",
      "False \n",
      "unexpcted\n",
      "Corrected \n",
      "unexpected\n",
      "\n",
      "True \n",
      "standardizing:\n",
      "False \n",
      "stanerdizing\n",
      "Corrected \n",
      "standing\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 7 \n",
    "\n",
    "# Correcting the first 20 words of spell_test.txt\n",
    "\n",
    "import subprocess\n",
    "\n",
    "with open('./data/spell_test.txt') as file:\n",
    "    # reading each line \n",
    "    j = 0\n",
    "    for line in file:\n",
    "        j = j+1\n",
    "        if j == 20:\n",
    "            break\n",
    "        i = 0\n",
    "        # reading each word       \n",
    "        for word in line.split():\n",
    "            i = i+1\n",
    "            if i == 1:\n",
    "                print(\"True \\n{}\".format(word))\n",
    "            elif i == 2:\n",
    "                print(\"False \\n{}\".format(word))\n",
    "                print(\"Corrected \")\n",
    "                subprocess.call(['bash','predict.sh', './fsts/S.binfst' , word])\n",
    "                print('\\n')\n",
    "            else:\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e4c726",
   "metadata": {},
   "source": [
    "**Part 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9d89e2b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n\t<eps>\r\n"
     ]
    }
   ],
   "source": [
    "# Step 8\n",
    "\n",
    "!./word_edits.sh abandonned abandoned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7d4b0a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a file with the edits in wiki.txt\n",
    "\n",
    "with open('./data/wiki.txt') as file:\n",
    "    # reading each line \n",
    "    for line in file:\n",
    "        # reading words       \n",
    "        words = line.split()\n",
    "        subprocess.call(['bash','word_edits_savetofile.sh', words[0] , words[1]])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "de039725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "342\n",
      "600\n"
     ]
    }
   ],
   "source": [
    "# Create Dict with frequency(value) of each edit(key)\n",
    "\n",
    "Edits = {}\n",
    "with open('./data/edits.txt') as file:\n",
    "    # reading each line   \n",
    "    for line in file:\n",
    "        # reading each edit      \n",
    "        edit =  tuple(line.split())\n",
    "        if edit not in Edits:\n",
    "            Edits[edit] = 1\n",
    "        else:\n",
    "            Edits[edit] = Edits[edit] + 1\n",
    "\n",
    "print(len(Edits))\n",
    "print(24 + 24 + 24*23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ea82f8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log10\n",
    "\n",
    "# E .fst (edit weight == -log10(edit freq))\n",
    "\n",
    "total = sum(Edits.values())\n",
    "\n",
    "with open(\"./fsts/E.fst\",'w') as f:\n",
    "    for i in range(97,123):\n",
    "        f.write(\"0\\t0\\t{}\\t{}\\t0\\n\".format(chr(i),chr(i))) # chr -> chr\n",
    "        \n",
    "        if (chr(i), '<eps>') not in Edits:\n",
    "            f.write(\"0\\t0\\t{}\\t<eps>\\t10000\\n\".format(chr(i))) # chr -> <eps>\n",
    "        else:\n",
    "            f.write(\"0\\t0\\t{}\\t<eps>\\t{}\\n\".format(chr(i),-log10(Edits[(chr(i),'<eps>')]/total))) # chr -> <eps>\n",
    "            \n",
    "        if ('<eps>', chr(i)) not in Edits:\n",
    "            f.write(\"0\\t0\\t<eps>\\t{}\\t10000\\n\".format(chr(i))) # <eps> -> chr\n",
    "        else:\n",
    "            f.write(\"0\\t0\\t<eps>\\t{}\\t{}\\n\".format(chr(i),-log10(Edits[('<eps>', chr(i))]/total))) # <eps> -> chr\n",
    "        \n",
    "        for j in range(97,123):\n",
    "            if j != i:\n",
    "                if (chr(i), chr(j)) not in Edits:\n",
    "                    f.write(\"0\\t0\\t{}\\t{}\\t10000\\n\".format(chr(i),chr(j))) # chr -> chr\n",
    "                else:\n",
    "                    f.write(\"0\\t0\\t{}\\t{}\\t{}\\n\".format(chr(i),chr(j),-log10(Edits[(chr(i), chr(j))]/total))) # chr -> chr\n",
    "    \n",
    "    f.write(\"0\\t0\\n\") # end state\n",
    "                \n",
    "!fstcompile -isymbols=./vocab/chars.syms -osymbols=./vocab/chars.syms ./fsts/E.fst ./fsts/E.binfst\n",
    "# !fstdraw -isymbols=./vocab/chars.syms -osymbols=./vocab/chars.syms -portrait ./fsts/L.binfst | dot -Tpng >./fsts/L.png\n",
    "# !display ./fsts/L.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "354fcbf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wit"
     ]
    }
   ],
   "source": [
    "# Compose E with V (Dictionary acceptor) to build the spell checker EV\n",
    "\n",
    "!fstarcsort --sort_type=olabel ./fsts/E.binfst ./fsts/E.binfst\n",
    "!fstarcsort --sort_type=ilabel ./fsts/V_opt.binfst ./fsts/V_opt.binfst\n",
    "!fstcompose ./fsts/E.binfst ./fsts/V_opt.binfst ./fsts/EV.binfst\n",
    "\n",
    "!./predict.sh ./fsts/EV.binfst cwt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e12ee477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clit"
     ]
    }
   ],
   "source": [
    "!./predict.sh ./fsts/EV.binfst cit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f01089da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theatre"
     ]
    }
   ],
   "source": [
    "!./predict.sh ./fsts/EV.binfst antheaterry "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "63387ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True \n",
      "contented:\n",
      "False \n",
      "contenpted\n",
      "Corrected \n",
      "contented\n",
      "\n",
      "True \n",
      "beginning:\n",
      "False \n",
      "begining\n",
      "Corrected \n",
      "beginning\n",
      "\n",
      "True \n",
      "problem:\n",
      "False \n",
      "problam\n",
      "Corrected \n",
      "problem\n",
      "\n",
      "True \n",
      "driven:\n",
      "False \n",
      "dirven\n",
      "Corrected \n",
      "driven\n",
      "\n",
      "True \n",
      "ecstasy:\n",
      "False \n",
      "exstacy\n",
      "Corrected \n",
      "exactly\n",
      "\n",
      "True \n",
      "juice:\n",
      "False \n",
      "guic\n",
      "Corrected \n",
      "guil\n",
      "\n",
      "True \n",
      "locally:\n",
      "False \n",
      "localy\n",
      "Corrected \n",
      "local\n",
      "\n",
      "True \n",
      "compare:\n",
      "False \n",
      "compair\n",
      "Corrected \n",
      "compare\n",
      "\n",
      "True \n",
      "pronunciation:\n",
      "False \n",
      "pronounciation\n",
      "Corrected \n",
      "pronouncing\n",
      "\n",
      "True \n",
      "transportability:\n",
      "False \n",
      "transportibility\n",
      "Corrected \n",
      "respectability\n",
      "\n",
      "True \n",
      "minuscule:\n",
      "False \n",
      "miniscule\n",
      "Corrected \n",
      "mince\n",
      "\n",
      "True \n",
      "independent:\n",
      "False \n",
      "independant\n",
      "Corrected \n",
      "independent\n",
      "\n",
      "True \n",
      "arranged:\n",
      "False \n",
      "aranged\n",
      "Corrected \n",
      "arranged\n",
      "\n",
      "True \n",
      "poetry:\n",
      "False \n",
      "poartry\n",
      "Corrected \n",
      "poetry\n",
      "\n",
      "True \n",
      "level:\n",
      "False \n",
      "leval\n",
      "Corrected \n",
      "level\n",
      "\n",
      "True \n",
      "basically:\n",
      "False \n",
      "basicaly\n",
      "Corrected \n",
      "busily\n",
      "\n",
      "True \n",
      "triangular:\n",
      "False \n",
      "triangulaur\n",
      "Corrected \n",
      "triangular\n",
      "\n",
      "True \n",
      "unexpected:\n",
      "False \n",
      "unexpcted\n",
      "Corrected \n",
      "unexpected\n",
      "\n",
      "True \n",
      "standardizing:\n",
      "False \n",
      "stanerdizing\n",
      "Corrected \n",
      "sneezing\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 7 \n",
    "\n",
    "# Correcting the first 20 words of spell_test.txt with EV\n",
    "\n",
    "import subprocess\n",
    "\n",
    "with open('./data/spell_test.txt') as file:\n",
    "    # reading each line \n",
    "    j = 0\n",
    "    for line in file:\n",
    "        j = j+1\n",
    "        if j == 20:\n",
    "            break\n",
    "        i = 0\n",
    "        # reading each word       \n",
    "        for word in line.split():\n",
    "            i = i+1\n",
    "            if i == 1:\n",
    "                print(\"True \\n{}\".format(word))\n",
    "            elif i == 2:\n",
    "                print(\"False \\n{}\".format(word))\n",
    "                print(\"Corrected \")\n",
    "                subprocess.call(['bash','predict.sh', './fsts/EV.binfst' , word])\n",
    "                print('\\n')\n",
    "            else:\n",
    "                break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
